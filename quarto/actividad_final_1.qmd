---
title: "Vecindad por distancia y matrices de vecindad"
author: "Alex Bajaña"
date: "2024-07-22"
output: html_document
---

## Aplicación: Todo lo que hemos aprendido juntos

No olviden siempre dejar comentando sus `install.packages` eso evitará que se reinstalen paquetes en el entorno de trabajo. Esto también ayudará a que sus scripts sean más rápidos y evitará problemas de instalación de paquetes que ya tienen instalados.

```{r}
# Instalar y cargar los paquetes necesarios
# install.packages(c("sf", "ggplot2", "dplyr"))
library(sf)
library(tidyverse)
library(osmdata)
library(spdep)
library(cowplot)
```

Una de nuestras clases fue sobre **funciones**. Decíamos que una función se compone de tres partes: **nombre**, **argumentos**, **cuerpo**. Vamos a crear una función que nos permita obtener los datos de OpenStreetMaps del Distrito Metropolitano de Quito. 

Es importante modularizar el código en funciones porque nos permite reutilizar código, hacerlo más legible y mantener una estructura más ordenada.

```{r}
# Función para obtener datos de OpenStreetMaps para una característica específica
obtener_osm_data <- function(value, feature) {
  
  bbox <- getbb("Guaranda, Ecuador") # Parte fija: define la caja de delimitación
  
  osm_query <- opq(bbox) %>%
    add_osm_feature(value = value, key = feature) %>% 
    osmdata_sf()
  
  osm_points <- osm_query$osm_points
  
  return(osm_points)
}
```

Recuerden que OpenStreetMaps tiene una serie de etiquetas que nos permiten obtener información específica. Por ejemplo, si queremos obtener información sobre los hospitales, usamos la etiqueta `amenity` con el valor `hospital`. Vamos a obtener los datos de los hospitales en Quito. El objeto `osm_query` contiene: `osm_points`, `osm_lines`, `osm_polygons`. 

Es fundamental entender las estructuras de datos que estamos manejando para poder trabajar de manera eficiente con ellas.

```{r}
# Obtener datos de diferentes amenidades
amenidades <- c("hospital", "clinic", "school", "kindergarten") %>% 
  map(~obtener_osm_data(.x, "amenity") %>% 
        mutate(amenidad = .x))

# Consolidamos en un solo data.frame
amenidades <- amenidades %>% reduce(bind_rows)
```

Grafiquemos las amenidades en un mapa para visualizar su distribución en Quito. Primero vamos a cargar los datos de las zonas censales de Quito. Trabajar con datos espaciales requiere entender bien el sistema de coordenadas y cómo transformar y manipular los datos geoespaciales.

```{r}
# Cargar y preparar los datos de zonas censales
zonas <- st_read("../data/GEODATABASE_NACIONAL_2021/GEODATABASE_NACIONAL_2021.gdb/", layer = "zon_a")

dmq_zonas <- zonas %>% filter(str_detect(zon, "^020150"))
```

Nos quedamos solo con las amenidades que están dentro de los polígonos de Quito. Filtrar y transformar datos espaciales es una habilidad clave al trabajar con SIG.

```{r}
# Filtrar amenidades dentro de los polígonos de Quito
amenidades <- amenidades %>% 
  st_transform(crs = st_crs(dmq_zonas)) %>% 
  st_intersection(dmq_zonas)
```

Ahora graficamos todo junto con `ggplot2`, pero antes vamos a corregir las etiquetas de la amenidad con `forcats`. Manipular y limpiar datos es crucial para asegurar que los análisis y visualizaciones sean precisos.

```{r}
# Corregir las etiquetas de las amenidades
amenidades <- amenidades %>% 
  mutate(amenidad = fct_recode(amenidad,
                                "Hospital" = "hospital",
                                "Clinica" = "clinic",
                                "Escuelas" = "school",
                                "Kinders" = "kindergarten"))
```

```{r}
# Graficar amenidades en Quito
ggplot() +
  geom_sf(data = dmq_zonas, color = "darkgrey", size = 0.5) +
  geom_sf(data = amenidades, aes(color = amenidad), size = 1, alpha = 0.6) +
  scale_color_brewer(palette = "Spectral") +
  theme_minimal() +
  labs(title = "Amenidades en Quito",
       subtitle = "Considerando salud y educación para niños menores a 5 años",
       caption = "Fuente: OpenStreetMaps",
       color = "Amenidad:") 
```

Vamos a usar `st_union` para contar cuántas amenidades hay en cada zona censal. Pero antes vamos a crear en amenidades una variable categórica que tenga las categorías `educacion` y `salud` con `forcats` y la función `fct_collapse`. Las variables categóricas nos permiten agrupar datos y realizar análisis más detallados.

```{r}
# Crear variable categórica para clasificar amenidades
amenidades <- amenidades %>% 
  mutate(categoria = fct_collapse(amenidad,
                                  educacion = c("Escuelas", "Kinders"),
                                  salud = c("Hospital", "Clinica")))
```

Ahora contamos cuántas amenidades hay en cada zona censal. La función `st_join` nos permite unir datos espaciales basados en su relación geográfica.

```{r}
# Contar amenidades en cada zona censal
contar_amenidades <- amenidades %>% 
  select(-any_of(names(dmq_zonas))) %>%
  st_join(dmq_zonas, join = st_within) 

contar_amenidades <- contar_amenidades %>% 
  as_tibble() %>% 
  group_by(zon, categoria) %>%
  summarise(n_amen = n())
```

Como hay zonas que no tienen ninguna de las amenidades que estamos considerando, vamos a rellenar con ceros. Mostremos dos mapas de calor que tengan una paleta de gradiente de blanco a verde para educación y de blanco a púrpura para salud. Luego mostramos los dos mapas de calor con `cowplot`. 

Rellenar valores faltantes es crucial para evitar errores en el análisis posterior.

```{r}
# Crear mapa de calor para amenidades de salud
mapa_calor_salud <- contar_amenidades %>%
  filter(categoria == "salud")

mapa_calor_salud <- dmq_zonas %>% 
  left_join(mapa_calor_salud, by = "zon") %>%
  mutate(n_amen = replace_na(n_amen, 0)) %>% 
  ggplot() +
  geom_sf(aes(fill = n_amen), color = NA) +
  scale_fill_viridis_c(option = "D") +
  theme_minimal() +
  labs(title = "a) Amenidades de Salud",
       fill = "Amenidades") 

# Crear mapa de calor para amenidades de educación
mapa_calor_educacion <- contar_amenidades %>%
  filter(categoria == "educacion")

mapa_calor_educacion <- dmq_zonas %>%
  left_join(mapa_calor_educacion, by = "zon") %>%
  mutate(n_amen = replace_na(n_amen, 0)) %>% 
  ggplot() +
  geom_sf(aes(fill = n_amen), color = NA) +
  scale_fill_viridis_c(option = "E") +
  theme_minimal() +
  labs(title = "b) Amenidades de Educación",
       fill = "Amenidades") 

# Mostrar los dos mapas de calor juntos
plot_grid(mapa_calor_salud, mapa_calor_educacion, ncol = 2)
```

Ahora del censo agrupado con el que trabajamos el índice de Moran, vamos a traer la variable `n_hijos` y vamos a unir con los datos de las amenidades. Vamos a hacer un mapa de calor de los niños menores a 5 años por hogar en Quito. 

Es importante entender cómo los datos del censo pueden ser utilizados para análisis geoespaciales.

```{r}
# Cargar datos del censo
censo_hogar <- read_tsv("../data/censo_hogar.csv")

# Filtrar hogares con niños menores de 5 años
censo_hogar <- censo_hogar %>% 
  filter(P03 <= 5)

# Agrupar datos del censo por zona censal
censo_hogar_s <- censo_hogar %>% 
  mutate(zon = str_c(I01, I02, I03, I04)) %>% 
  group_by(zon) %>%
  summarise(n_hijos = sum(n_hijos, na.rm = TRUE)) 
```

A la tabla de amenidades le damos un formato ancho en función de la variable `categoria`. El formato ancho facilita ciertos tipos de análisis y visualización.

```{r}
# Convertir tabla de amenidades a formato ancho
data_modelo <- contar_amenidades %>% 
  pivot_wider(names_from = categoria, values_from = n_amen)
```

Unimos las tablas de amenidades y censo. Unir datos de diferentes fuentes es una habilidad esencial en el análisis de datos.

```{r}
# Unir datos de amenidades y censo
data_modelo <- data_modelo %>% 
  right_join(censo_hogar_s, by = "zon")
```

```{r}
# Rellenar valores faltantes con ceros
data_modelo <- data_modelo %>% mutate(across(educacion:n_hijos, ~replace_na(.x, 0)))
```

Hacemos la regresión lineal de los niños menores a 5 años por hogar en función de las amenidades de salud y educación. Las regresiones lineales nos permiten entender la relación entre variables dependientes e independientes.

```{r}
# Realizar regresión lineal
modelo <- lm(n_hijos ~ salud + educacion, data = data_modelo)

# Mostrar resumen del modelo
summary(modelo)
```

Ahora calculamos la matriz de vecindad binaria. Las matrices de vecindad son fundamentales para análisis espaciales, ya que definen las relaciones espaciales entre las observaciones.

```{r}
# Crear matriz de vecindad binaria
vecinos <- poly2nb(dmq_zonas, queen = TRUE)
```

Y armamos la matriz de pesos. La matriz de pesos asigna una medida de relación entre las observaciones vecinas, crucial para muchos análisis espaciales.

```{r}
# Crear matriz de pesos
vecinos_pesos <- nb2listw(vecinos, style = "W", zero.policy = TRUE)
```

Calculamos el índice de Moran. El índice de Moran nos permite detectar la autocorrelación espacial, que es la similitud de valores en una ubicación espacial.

```{r, warning=FALSE}
# Unir datos de n_hijos con zonas censales y reemplazar valores faltantes
dmq_zonas <- left_join(dmq_zonas, data_modelo, by = "zon") %>% mutate(n_hijos = replace_na(n_hijos, 0))

# Calcular índice de Moran
moran <- moran.test(dmq_zonas$n_hijos, vecinos_pesos, alternative = "greater")

moran
```

Sabemos que hay presencia de autocorrelación espacial positiva en la variable `n_hijos` por hogar en Quito. Sin embargo, para poder determinar la presencia de autocorrelación de los residuos del modelo de regresión lineal, vamos a hacer un mapa de los residuos del modelo.

Los residuos del modelo deben ser revisados para entender si el modelo es adecuado o si hay patrones espaciales no capturados.

```{r, warning=FALSE}
# Realizar test de Moran sobre los residuos del modelo de regresión lineal
lm_moran_test <- lm.morantest(modelo, vecinos_pesos)

lm_moran_test

# Realizar pruebas LM para detectar autocorrelación espacial y errores espaciales
lm.LMtests(modelo, vecinos_pesos, test=c("LMerr", "LMlag", "RLMerr", "RLMlag", "SARMA"))
```

La función `lm.LMtests` en el paquete `spdep` se utiliza para realizar una serie de pruebas de especificación Lagrange Multiplier (LM) sobre los residuos de un modelo de regresión lineal para detectar la presencia de autocorrelación espacial y errores espaciales. Las pruebas que has especificado incluyen:

1. **LMerr (Lagrange Multiplier test for spatial error model)**:
   - Esta prueba evalúa si hay autocorrelación espacial en los errores del modelo de regresión.
   
2. **LMlag (Lagrange Multiplier test for spatial lag model)**:
   - Esta prueba evalúa si existe una relación espacial en la variable dependiente del modelo, es decir, si el valor de la variable dependiente en una ubicación está influenciado por los valores de la variable dependiente en las ubicaciones vecinas.

3. **RLMerr (Robust Lagrange Multiplier test for spatial error model)**:
   - Es una versión robusta de la prueba LMerr, que controla la influencia de la especificación del modelo espacial.

4. **RLMlag (Robust Lagrange Multiplier test for spatial lag model)**:
   - Es una versión robusta de la prueba LMlag, que controla la influencia de la especificación del modelo espacial.

5. **SARMA (Lagrange Multiplier test for SARMA model)**:
   - Esta prueba evalúa una combinación de autocorrelación espacial en los errores y en la variable dependiente.

El propósito de estas pruebas es determinar si hay autocorrelación espacial en los residuos del modelo de regresión y si el modelo necesita ser ajustado para incorporar componentes espaciales. Revisando cada una de las pruebas proporcionará información sobre la necesidad de ajustar tu modelo, ya sea utilizando un modelo de error espacial (Spatial Error Model), un modelo de retardo espacial (Spatial Lag Model) o un modelo combinado SARMA (Spatial AutoRegressive Moving Average).

Al final, recuerden siempre revisar los resultados de sus análisis para entender los patrones y relaciones en sus datos. La exploración y visualización de datos son herramientas poderosas para tomar decisiones informadas.
