---
title: "Principios de probabilidad"
format: html
editor: visual
---

### 1. Definiciones de Probabilidad  

En la estadística, la probabilidad se define como una medida de la certeza de que un evento ocurra. Se denota comúnmente por$P(A)$, donde$A$ es el evento de interés. La probabilidad de cualquier evento se encuentra en el intervalo$[0, 1]$, donde 0 indica la imposibilidad del evento y 1 indica certeza absoluta.

#### Dominio de la Función

El dominio de una función de probabilidad es el conjunto de todos los posibles resultados de un experimento aleatorio. Por ejemplo, si lanzamos una moneda, el dominio es$\{cara, cruz\}$.

#### Función de Distribución
La función de distribución, también conocida como función de probabilidad, asigna a cada posible resultado un valor de probabilidad. Para una variable aleatoria discreta$X$, la función de distribución de probabilidad$p(x)$ está definida como:
$$p(x) = P(X = x)$$

#### Distribución Acumulada

La función de distribución acumulada (FDA), denotada como$F(x)$, es la probabilidad de que la variable aleatoria$X$ tome un valor menor o igual a$x$. Matemáticamente, se expresa como:
$$F(x) = P(X \leq x)$$

### 2. Distribuciones Más Conocidas

A continuación, se presenta una tabla que resume algunas de las distribuciones más comunes en estadística, incluyendo sus usos, la fórmula de la media y la varianza.

| Nombre de la Distribución | Usos Comunes                                      | Fórmula de la Media                          | Fórmula de la Varianza                       |
|---------------------------|---------------------------------------------------|---------------------------------------------|---------------------------------------------|
| Normal                    | Datos continuos, fenómenos naturales              |$\mu$                                     |$\sigma^2$                                |
| Poisson                   | Número de eventos en un intervalo de tiempo/espacio|$\lambda$                                 |$\lambda$                                 |
| Uniforme                  | Eventos igualmente probables                      |$\frac{a + b}{2}$                         |$\frac{(b - a)^2}{12}$                    |
| Binomial                  | Número de éxitos en$n$ ensayos                 |$np$                                      |$np(1-p)$                                 |
| Geométrica                | Ensayos hasta el primer éxito                     |$\frac{1}{p}$                             |$\frac{1-p}{p^2}$                         |
| Exponencial               | Tiempo entre eventos                              |$\frac{1}{\lambda}$                       |$\frac{1}{\lambda^2}$                     |
| Beta                      | Proporciones y probabilidades                     |$\frac{\alpha}{\alpha + \beta}$           |$\frac{\alpha \beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}$ |
| Gamma                     | Tiempo hasta la ocurrencia de$k$ eventos       |$\alpha \beta$                            |$\alpha \beta^2$                          |

### 3. El Teorema de Bayes

El Teorema de Bayes es una herramienta fundamental en la teoría de probabilidad, que permite actualizar las probabilidades iniciales (a priori) basadas en nueva información (evidencia). 

Este teorema se expresa como:

$$P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}$$

Donde$P(A|B)$ es la probabilidad de que ocurra$A$ dado que$B$ ha ocurrido,$P(B|A)$ es la probabilidad de que ocurra$B$ dado que$A$ ha ocurrido,$P(A)$ es la probabilidad a priori de$A$, y$P(B)$ es la probabilidad total de$B$.

La probabilidad conjunta de dos eventos$A$ y$B$ está dada por:

$$P(A \cap B) = P(B|A) \cdot P(A)$$

Para la suma de probabilidades de eventos mutuamente excluyentes$A_1, A_2, \ldots, A_n$, la fórmula es:

$$P(B) = \sum_{i=1}^{n} P(B|A_i) \cdot P(A_i)$$

Estas fórmulas son cruciales para realizar inferencias basadas en el teorema de Bayes, permitiendo ajustar nuestras creencias sobre la ocurrencia de eventos a medida que se obtiene nueva información.

Claro, vamos a desglosar el proceso de cálculo de la probabilidad posterior usando el Teorema de Bayes, siguiendo la lógica del ejemplo y explicándolo de manera sencilla.

### La temperatura en Pichincha

Tenemos datos de temperatura en Pichincha, y queremos predecir la temperatura en un punto específico para hoy, basándonos en la temperatura en ese punto el día anterior. Supongamos que:

-$A$ es la temperatura en el punto específico hoy.
-$B$ es la temperatura en ese punto ayer.

### Paso 1: Probabilidad a Priori ($P(A)$)

La probabilidad a priori ($P(A)$) es nuestra mejor estimación de la temperatura de hoy sin considerar la información del día anterior. Esta probabilidad se basa en datos históricos. Por ejemplo, si históricamente las temperaturas siguen una distribución normal con una media ($\mu$) de 20 grados y una desviación estándar ($\sigma$) de 5 grados, entonces la probabilidad de que la temperatura de hoy sea$A$ está dada por:

$$P(A) = \frac{1}{\sigma \sqrt{2\pi}} \exp\left(-\frac{(A - \mu)^2}{2\sigma^2}\right)$$

### Paso 2: Probabilidad Condicional ($P(B|A)$)

La probabilidad condicional ($P(B|A)$) es la probabilidad de que la temperatura ayer ($B$) sea lo que fue, dado que la temperatura hoy ($A$) es lo que estamos tratando de predecir. Utilizamos una relación basada en datos históricos. Para simplificar, asumimos que si la temperatura de hoy es$A$, la temperatura de ayer también sigue una distribución normal con media$A$ y la misma desviación estándar$\sigma$.

$$P(B|A) = \frac{1}{\sigma \sqrt{2\pi}} \exp\left(-\frac{(B - A)^2}{2\sigma^2}\right)$$

### Paso 3: Probabilidad Total ($P(B)$)

La probabilidad total ($P(B)$) es la probabilidad de que la temperatura de ayer sea$B$ sin importar la temperatura de hoy. Esto también se basa en datos históricos y sigue la misma distribución normal con media histórica$\mu$ y desviación estándar$\sigma$.

$$P(B) = \frac{1}{\sigma \sqrt{2\pi}} \exp\left(-\frac{(B - \mu)^2}{2\sigma^2}\right)$$

### Paso 4: Aplicación del Teorema de Bayes

Usamos el Teorema de Bayes para actualizar nuestra probabilidad a priori ($P(A)$) en función de la información del día anterior ($B$):

$$P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}$$

Esta es nuestra probabilidad posterior ($P(A|B)$), la probabilidad de que la temperatura hoy sea$A$ dado que la temperatura ayer fue$B$.

### Ejemplo Numérico

Supongamos que:
- La media histórica ($\mu$) es 20 grados.
- La desviación estándar ($\sigma$) es 5 grados.
- La temperatura ayer ($B$) fue 22 grados.
- Queremos calcular la probabilidad de que la temperatura hoy ($A$) sea 21 grados.

1. **Probabilidad a Priori ($P(A = 21)$)**:
$$P(A = 21) = \frac{1}{5 \sqrt{2\pi}} \exp\left(-\frac{(21 - 20)^2}{2 \cdot 5^2}\right)$$

2. **Probabilidad Condicional ($P(B = 22|A = 21)$)**:
$$P(B = 22|A = 21) = \frac{1}{5 \sqrt{2\pi}} \exp\left(-\frac{(22 - 21)^2}{2 \cdot 5^2}\right)$$

3. **Probabilidad Total ($P(B = 22)$)**:
$$P(B = 22) = \frac{1}{5 \sqrt{2\pi}} \exp\left(-\frac{(22 - 20)^2}{2 \cdot 5^2}\right)$$

4. **Probabilidad Posterior ($P(A = 21|B = 22)$)**:
$$P(A = 21|B = 22) = \frac{P(B = 22|A = 21) \cdot P(A = 21)}{P(B = 22)}$$

Al calcular cada uno de estos valores usando las fórmulas de la distribución normal, puedes obtener la probabilidad posterior.

### Implementación en R

A continuación, se muestra cómo calcular esto en R:

```{r}

# Definir los parámetros
mu <- 20
sigma <- 5
A <- 21
B <- 22

# Probabilidad a priori
prior_prob <- dnorm(A, mean = mu, sd = sigma)

# Probabilidad condicional
conditional_prob <- dnorm(B, mean = A, sd = sigma)

# Probabilidad total
total_prob <- dnorm(B, mean = mu, sd = sigma)

# Probabilidad posterior
posterior_prob <- (conditional_prob * prior_prob) / total_prob

posterior_prob
```

Este código calculará la probabilidad posterior de que la temperatura hoy sea 21 grados dado que ayer fue 22 grados, usando el Teorema de Bayes.